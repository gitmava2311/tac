{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7f31c4-63b3-4c06-97f1-e21d03d7b56c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# TP4 : Développement du plateau du Heysel entre 1847 et 1978"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6eeff4a-1fc9-414a-87f9-83041f630a82",
   "metadata": {},
   "source": [
    "## Préparation du corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037e8514-36ca-41c3-9611-33000b92c956",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce5ae60-7bb7-4de4-876f-6c7dcb6cc67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import sys\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from IPython.display import Image\n",
    "import mmap\n",
    "from difflib import SequenceMatcher\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "from openpyxl.utils import get_column_letter\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c549813-e441-4dda-92da-41de321f5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18ba87dd-3dfc-4f45-8737-975428ffa212",
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtenir le nom des rue sur nominatim pour le chaque latitude et longitude du plateau du Heysel et les écrire dans mon fichier de recherche\n",
    "\n",
    "fichier = open(\"../data/rues.txt\", \"a\")\n",
    "\n",
    "latmmax = 50.90350397899814\n",
    "longmin = 4.328493534801743\n",
    "latmin= 50.88509135160375\n",
    "longmax = 4.354090559446083\n",
    "\n",
    "while longmin <= longmax:\n",
    "    longmin=longmin+0.0010000000000000\n",
    "    x=latmin\n",
    "    while x <= latmmax:\n",
    "        url = \"https://nominatim.openstreetmap.org/reverse\"\n",
    "        data = {'lat': x, 'lon': longmin,'format': 'json'}\n",
    "        resp = requests.get(url, data)\n",
    "        json_list = json.loads(resp.text)\n",
    "        try:\n",
    "            fichier.write(json_list[\"address\"][\"road\"] + \"\\n\")\n",
    "        except KeyError:\n",
    "            fichier.write(\"erreur rue\" + \"\\n\")\n",
    "        x=x+0.0050000000000\n",
    " \n",
    "    \n",
    "fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ae78a03-cd4b-4f8a-b454-b143743bc5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirer les doublons, Esplanade, A212 et erreur rue du fichier de recherche\n",
    "ls = []\n",
    "\n",
    "with open(\"../data/rues.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        if line.lower() not in ls and line!=\"erreur rue\"+\"\\n\" and line!=\"Esplanade\"+\"\\n\" and line!=\"A12\"+\"\\n\":\n",
    "            ls.append(line.lower())\n",
    "\n",
    "with open(\"../data/rues.txt\", 'w') as file:\n",
    "    for line in ls:\n",
    "        file.write(line)\n",
    "        \n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fd8ee7-de85-4898-9da7-21603c80e133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mettre un nom de rue par ligne dans une langue (FR ou NL)\n",
    "ls = []\n",
    "stopwords1=(\"jean joseph\", \"jean\", \"joseph\", \"arthur\", \"ernest\", \"gustave\", \"adrien\", \"guillaume\", \"edouard\", \"léopold\", \"leopold\", \"jean\", \"baptiste\", \"reper\", \"moens\", \"sentier\", \n",
    "               \"smet\", \"félix\", \"felix\", \"stevens\", \"pierre\", \"emile\", \"avenue\", \"place\", \"rue \",\"de l'\", \"de la \", \"van \", \"boulevard\", \"chaussée\", \"des \", \" la \", \"gros\", \"laeken\",\n",
    "           \"anne\", \"belgique\", \"baptiste \", \"de \", \"hêtres \", \"du \", \"sports\", \"square\", \"sainte\", \"saint\", \"compte\", \"graaf\", \"drève\", \"parc\", \"royal\", \"koninklijk\", \"palais\")\n",
    "\n",
    "with open(\"../data/rues.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            elems = line.split(\"-\")\n",
    "            FR = elems[0]\n",
    "            NL = elems[1]\n",
    "            for mot in stopwords1:\n",
    "                if mot in FR:\n",
    "                    FRshort= FR.replace(mot,'')\n",
    "                    FR=FRshort\n",
    "                if mot in NL:\n",
    "                    NLshort= NL.replace(mot,'')\n",
    "                    NL=NLshort\n",
    "        except KeyError:\n",
    "            ls.append(line)\n",
    "        ls.append(FR.strip() + \"\\n\")\n",
    "        ls.append(NL.strip() + \"\\n\")\n",
    "file.close()\n",
    "            \n",
    "ls.append(\"esplanade\\n\")            \n",
    "ls.append(\"atomium\\n\")\n",
    "ls.append(\"mini-europe\\n\")   \n",
    "ls.append(\"heysel\\n\") \n",
    "ls.append(\"expositions\\n\")\n",
    "ls.append(\"exposition\\n\")\n",
    "ls.append(\"expo\\n\") \n",
    "ls.append(\"trademart\\n\") \n",
    "ls.append(\"brupark\\n\") \n",
    "ls.append(\"planétarium\\n\") \n",
    "ls.append(\"stade\\n\")\n",
    "ls.append(\"meli\\n\")\n",
    "ls.append(\"universelle\\n\") \n",
    "ls.append(\"stevens-delannoy\\n\")\n",
    "ls.append(\"reper-vreven\\n\")\n",
    "ls.append(\"saint-lambert\\n\")\n",
    "ls.append(\"sainte-anne\\n\")\n",
    "ls.append(\"stuyvenberg\\n\")\n",
    "ls.append(\"château\\n\")\n",
    "ls.append(\"belvédère\\n\")\n",
    "ls.append(\"kasteel\\n\")\n",
    "ls.append(\"plateau\\n\")\n",
    "ls.append(\"japonaise\\n\")\n",
    "ls.append(\"chinois\\n\")\n",
    "ls.append(\"moyen-orient\\n\")\n",
    "\n",
    "           \n",
    "with open(\"../data/rues.txt\", 'w') as file:\n",
    "    for line in ls:\n",
    "        if line!=\"\\n\":\n",
    "            file.write(line)     \n",
    "file.close()\n",
    "\n",
    "ls=[]\n",
    "with open(\"../data/rues.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        if line not in ls and line!=\"\\n\":\n",
    "            ls.append(line)\n",
    "\n",
    "with open(\"../data/rues.txt\", 'w') as file:\n",
    "    for line in ls:\n",
    "        file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60224a62-70c5-4d8e-926e-9b714354b030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crocq\n",
      "crocqlaan\n",
      "gehuchten\n",
      "gehuchtenplein\n",
      "disque\n",
      "schijfstraat\n",
      "romaine\n",
      "romeinsesteenweg\n",
      "masoin\n",
      "masoinlaan\n",
      "rommelaere\n",
      "rommelaerelaan\n",
      "houba\n",
      "strooper\n",
      "cresson\n",
      "waterkersstraat\n",
      "gilson\n",
      "gilsonstraat\n",
      "sportlaan\n",
      "ciboulette\n",
      "bieslookstraat\n",
      "bayet\n",
      "bayetlaan\n",
      "genévriers\n",
      "jeneverbomenstraat\n",
      "greef\n",
      "greeflaan\n",
      "kufferath\n",
      "kufferathlaan\n",
      "marathon\n",
      "marathonlaan\n",
      "madrid\n",
      "madridlaan\n",
      "peret\n",
      "peretstraat\n",
      "depaire\n",
      "centenaire\n",
      "eeuwfeestlaan\n",
      "vreven\n",
      "salu\n",
      "salustraat\n",
      "naeyer\n",
      "naeyerlaan\n",
      "science\n",
      "wetenschapslaan\n",
      "heymans\n",
      "heymansstraat\n",
      "sterckx\n",
      "sterckxstraat\n",
      "delannoy\n",
      "atomium\n",
      "atomiumplein\n",
      "strauwen\n",
      "strauwenstraat\n",
      "wauters\n",
      "wautersstraat\n",
      "hallier\n",
      "kreupelboslaan\n",
      "clémentine\n",
      "clementina\n",
      "lambert\n",
      "ebéniers\n",
      "ebbebomenlaan\n",
      "passerelle\n",
      "loopbruglaan\n",
      "trembles\n",
      "abelenlaan\n",
      "robiniers\n",
      "witte\n",
      "pourpres\n",
      "puperbeukenlaan\n",
      "setter\n",
      "setterweg\n",
      "médori\n",
      "médoristraat\n",
      "seringas\n",
      "wildejasmijnenlaan\n",
      "fernig\n",
      "ferniglaan\n",
      "tilleul\n",
      "dikkelindelaan\n",
      "amphore\n",
      "amforalaan\n",
      "dynastie\n",
      "vorstenhuisplein\n",
      "vorstenhuislaan\n",
      "forum\n",
      "forumlaan\n",
      "parklaan\n",
      "esplanade\n",
      "mini-europe\n",
      "heysel\n",
      "expositions\n",
      "exposition\n",
      "expo\n",
      "trademart\n",
      "brupark\n",
      "planétarium\n",
      "stade\n",
      "meli\n",
      "universelle\n",
      "stevens-delannoy\n",
      "reper-vreven\n",
      "saint-lambert\n",
      "sainte-anne\n",
      "stuyvenberg\n",
      "château\n",
      "belvédère\n",
      "kasteel\n",
      "plateau\n",
      "japonaise\n",
      "chinois\n",
      "moyen-orient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#vérifier le contenu du fichier de recherche\n",
    "fichier = open(\"../data/rues.txt\", \"r\")\n",
    "print (fichier.read())\n",
    "fichier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49b248e9-225f-4bc0-b985-3db92eee5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on met les fichiers txt en minuscule pour faciliter la recherche et on les sauvegarde sous data/tmp\n",
    "ls = []\n",
    "\n",
    "temp_path = '../data/tmp'\n",
    "txt_path = '../data/txt'\n",
    "\n",
    "for f in os.listdir(txt_path): \n",
    "    if os.path.isfile(os.path.join(txt_path, f)):\n",
    "        bulletin=txt_path + \"/\" + f\n",
    "        with open(bulletin, 'r') as filein:\n",
    "            for line in filein:\n",
    "                ls.append(line.lower())\n",
    "    filein.close()\n",
    "    bulletin_clean=temp_path + \"/\" + f   \n",
    "    with open(bulletin_clean, 'w') as fileout:\n",
    "        for line in ls:\n",
    "            fileout.write(line)\n",
    "    fileout.close()\n",
    "    ls = []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b80ad0b4-7246-404a-8b21-2a5b439c8cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on fait une liste de mots à corriger dans le corpus et on les mets dans fichier correction.txt - ici on va corriger les espaces dans les mots à rechercher\n",
    "ls = []\n",
    "mot=[]\n",
    "with open(\"../data/rues.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        string1=line.strip()\n",
    "        for lettre in string1:\n",
    "            mot.append(lettre)\n",
    "        ls.append(\" \".join(mot)+\" = \"+ string1 + \"\\n\")\n",
    "        mot=[]\n",
    "\n",
    "\n",
    "with open(\"../data/correction.txt\", 'w') as fileout:\n",
    "    for line in ls:\n",
    "        fileout.write(line)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0e09bbe-ae4b-4e01-b49a-e1db5a77e33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23c r o c q  corrigé par  crocq\n",
      "\n",
      "0c r o c q l a a n  corrigé par  crocqlaan\n",
      "\n",
      "5g e h u c h t e n  corrigé par  gehuchten\n",
      "\n",
      "0g e h u c h t e n p l e i n  corrigé par  gehuchtenplein\n",
      "\n",
      "94d i s q u e  corrigé par  disque\n",
      "\n",
      "0s c h i j f s t r a a t  corrigé par  schijfstraat\n",
      "\n",
      "103r o m a i n e  corrigé par  romaine\n",
      "\n",
      "0r o m e i n s e s t e e n w e g  corrigé par  romeinsesteenweg\n",
      "\n",
      "4m a s o i n  corrigé par  masoin\n",
      "\n",
      "0m a s o i n l a a n  corrigé par  masoinlaan\n",
      "\n",
      "32r o m m e l a e r e  corrigé par  rommelaere\n",
      "\n",
      "0r o m m e l a e r e l a a n  corrigé par  rommelaerelaan\n",
      "\n",
      "250h o u b a  corrigé par  houba\n",
      "\n",
      "36s t r o o p e r  corrigé par  strooper\n",
      "\n",
      "4c r e s s o n  corrigé par  cresson\n",
      "\n",
      "0w a t e r k e r s s t r a a t  corrigé par  waterkersstraat\n",
      "\n",
      "69g i l s o n  corrigé par  gilson\n",
      "\n",
      "0g i l s o n s t r a a t  corrigé par  gilsonstraat\n",
      "\n",
      "0s p o r t l a a n  corrigé par  sportlaan\n",
      "\n",
      "0c i b o u l e t t e  corrigé par  ciboulette\n",
      "\n",
      "0b i e s l o o k s t r a a t  corrigé par  bieslookstraat\n",
      "\n",
      "8b a y e t  corrigé par  bayet\n",
      "\n",
      "0b a y e t l a a n  corrigé par  bayetlaan\n",
      "\n",
      "2g e n é v r i e r s  corrigé par  genévriers\n",
      "\n",
      "0j e n e v e r b o m e n s t r a a t  corrigé par  jeneverbomenstraat\n",
      "\n",
      "590g r e e f  corrigé par  greef\n",
      "\n",
      "0g r e e f l a a n  corrigé par  greeflaan\n",
      "\n",
      "48k u f f e r a t h  corrigé par  kufferath\n",
      "\n",
      "0k u f f e r a t h l a a n  corrigé par  kufferathlaan\n",
      "\n",
      "11m a r a t h o n  corrigé par  marathon\n",
      "\n",
      "0m a r a t h o n l a a n  corrigé par  marathonlaan\n",
      "\n",
      "57m a d r i d  corrigé par  madrid\n",
      "\n",
      "0m a d r i d l a a n  corrigé par  madridlaan\n",
      "\n",
      "4p e r e t  corrigé par  peret\n",
      "\n",
      "0p e r e t s t r a a t  corrigé par  peretstraat\n",
      "\n",
      "238d e p a i r e  corrigé par  depaire\n",
      "\n",
      "181c e n t e n a i r e  corrigé par  centenaire\n",
      "\n",
      "0e e u w f e e s t l a a n  corrigé par  eeuwfeestlaan\n",
      "\n",
      "34v r e v e n  corrigé par  vreven\n",
      "\n",
      "841s a l u  corrigé par  salu\n",
      "\n",
      "0s a l u s t r a a t  corrigé par  salustraat\n",
      "\n",
      "141n a e y e r  corrigé par  naeyer\n",
      "\n",
      "0n a e y e r l a a n  corrigé par  naeyerlaan\n",
      "\n",
      "146s c i e n c e  corrigé par  science\n",
      "\n",
      "0w e t e n s c h a p s l a a n  corrigé par  wetenschapslaan\n",
      "\n",
      "29h e y m a n s  corrigé par  heymans\n",
      "\n",
      "0h e y m a n s s t r a a t  corrigé par  heymansstraat\n",
      "\n",
      "102s t e r c k x  corrigé par  sterckx\n",
      "\n",
      "0s t e r c k x s t r a a t  corrigé par  sterckxstraat\n",
      "\n",
      "87d e l a n n o y  corrigé par  delannoy\n",
      "\n",
      "62a t o m i u m  corrigé par  atomium\n",
      "\n",
      "0a t o m i u m p l e i n  corrigé par  atomiumplein\n",
      "\n",
      "9s t r a u w e n  corrigé par  strauwen\n",
      "\n",
      "0s t r a u w e n s t r a a t  corrigé par  strauwenstraat\n",
      "\n",
      "140w a u t e r s  corrigé par  wauters\n",
      "\n",
      "0w a u t e r s s t r a a t  corrigé par  wautersstraat\n",
      "\n",
      "2h a l l i e r  corrigé par  hallier\n",
      "\n",
      "0k r e u p e l b o s l a a n  corrigé par  kreupelboslaan\n",
      "\n",
      "65c l é m e n t i n e  corrigé par  clémentine\n",
      "\n",
      "0c l e m e n t i n a  corrigé par  clementina\n",
      "\n",
      "423l a m b e r t  corrigé par  lambert\n",
      "\n",
      "5e b é n i e r s  corrigé par  ebéniers\n",
      "\n",
      "0e b b e b o m e n l a a n  corrigé par  ebbebomenlaan\n",
      "\n",
      "8p a s s e r e l l e  corrigé par  passerelle\n",
      "\n",
      "0l o o p b r u g l a a n  corrigé par  loopbruglaan\n",
      "\n",
      "0t r e m b l e s  corrigé par  trembles\n",
      "\n",
      "0a b e l e n l a a n  corrigé par  abelenlaan\n",
      "\n",
      "14r o b i n i e r s  corrigé par  robiniers\n",
      "\n",
      "93w i t t e  corrigé par  witte\n",
      "\n",
      "6p o u r p r e s  corrigé par  pourpres\n",
      "\n",
      "0p u p e r b e u k e n l a a n  corrigé par  puperbeukenlaan\n",
      "\n",
      "5s e t t e r  corrigé par  setter\n",
      "\n",
      "0s e t t e r w e g  corrigé par  setterweg\n",
      "\n",
      "33m é d o r i  corrigé par  médori\n",
      "\n",
      "0m é d o r i s t r a a t  corrigé par  médoristraat\n",
      "\n",
      "0s e r i n g a s  corrigé par  seringas\n",
      "\n",
      "0w i l d e j a s m i j n e n l a a n  corrigé par  wildejasmijnenlaan\n",
      "\n",
      "10f e r n i g  corrigé par  fernig\n",
      "\n",
      "0f e r n i g l a a n  corrigé par  ferniglaan\n",
      "\n",
      "189t i l l e u l  corrigé par  tilleul\n",
      "\n",
      "0d i k k e l i n d e l a a n  corrigé par  dikkelindelaan\n",
      "\n",
      "4a m p h o r e  corrigé par  amphore\n",
      "\n",
      "0a m f o r a l a a n  corrigé par  amforalaan\n",
      "\n",
      "7d y n a s t i e  corrigé par  dynastie\n",
      "\n",
      "0v o r s t e n h u i s p l e i n  corrigé par  vorstenhuisplein\n",
      "\n",
      "0v o r s t e n h u i s l a a n  corrigé par  vorstenhuislaan\n",
      "\n",
      "38f o r u m  corrigé par  forum\n",
      "\n",
      "0f o r u m l a a n  corrigé par  forumlaan\n",
      "\n",
      "0p a r k l a a n  corrigé par  parklaan\n",
      "\n",
      "19e s p l a n a d e  corrigé par  esplanade\n",
      "\n",
      "0m i n i - e u r o p e  corrigé par  mini-europe\n",
      "\n",
      "538h e y s e l  corrigé par  heysel\n",
      "\n",
      "60e x p o s i t i o n s  corrigé par  expositions\n",
      "\n",
      "1596e x p o s i t i o n  corrigé par  exposition\n",
      "\n",
      "1619e x p o  corrigé par  expo\n",
      "\n",
      "2t r a d e m a r t  corrigé par  trademart\n",
      "\n",
      "0b r u p a r k  corrigé par  brupark\n",
      "\n",
      "28p l a n é t a r i u m  corrigé par  planétarium\n",
      "\n",
      "48s t a d e  corrigé par  stade\n",
      "\n",
      "134m e l i  corrigé par  meli\n",
      "\n",
      "139u n i v e r s e l l e  corrigé par  universelle\n",
      "\n",
      "0s t e v e n s - d e l a n n o y  corrigé par  stevens-delannoy\n",
      "\n",
      "0r e p e r - v r e v e n  corrigé par  reper-vreven\n",
      "\n",
      "0s a i n t - l a m b e r t  corrigé par  saint-lambert\n",
      "\n",
      "45s a i n t e - a n n e  corrigé par  sainte-anne\n",
      "\n",
      "15s t u y v e n b e r g  corrigé par  stuyvenberg\n",
      "\n",
      "272c h â t e a u  corrigé par  château\n",
      "\n",
      "6b e l v é d è r e  corrigé par  belvédère\n",
      "\n",
      "5k a s t e e l  corrigé par  kasteel\n",
      "\n",
      "31p l a t e a u  corrigé par  plateau\n",
      "\n",
      "13j a p o n a i s e  corrigé par  japonaise\n",
      "\n",
      "13c h i n o i s  corrigé par  chinois\n",
      "\n",
      "0m o y e n - o r i e n t  corrigé par  moyen-orient\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#on parcourt les bulletins et on fait les corrections nécéssaires.\n",
    "txt_path = '../data/tmp'\n",
    "ls=[]\n",
    "compteur=0\n",
    "\n",
    "with open(\"../data/correction.txt\", 'r') as filecorr:\n",
    "    for corr in filecorr:\n",
    "        try:\n",
    "            elems = corr.split(\"=\")\n",
    "            erreur = elems[0]\n",
    "            correction = elems[1]    \n",
    "            for f in os.listdir(txt_path): \n",
    "                if os.path.isfile(os.path.join(txt_path, f)):\n",
    "                    bulletin=txt_path + \"/\" + f\n",
    "                    with open(bulletin, 'r') as filein:\n",
    "                        for line in filein:\n",
    "                            if erreur in line:\n",
    "                                line=line.replace(erreur,correction)\n",
    "                                compteur+=1\n",
    "                            ls.append(line)\n",
    "                    with open(bulletin, 'w') as fileout:\n",
    "                        for line in ls:\n",
    "                            fileout.write(line)\n",
    "                    ls=[]\n",
    "            print(str(compteur) + \" \" + erreur + \" corrigé par \" + correction)\n",
    "            compteur=0\n",
    "        except KeyError:\n",
    "            print(\"erreur\")\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e748d62b-296a-4878-b086-ff096aac7bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = Workbook()\n",
    "\n",
    "dest_filename = '../data/frequences.xlsx'\n",
    "\n",
    "ws1 = wb.active\n",
    "ws1.title = \"frequence\"\n",
    "ws1['A1'] = \"bulletin\"\n",
    "ws1['B1'] = \"commune\"\n",
    "ws1['C1'] = \"année\"\n",
    "col=4\n",
    "with open(\"../data/rues.txt\", 'r') as file:\n",
    "    for line in file:\n",
    "        lettre=get_column_letter(col)\n",
    "        ws1[lettre + str(1)]= line\n",
    "        col+=1\n",
    "        \n",
    "        \n",
    "txt_path = '../data/tmp'\n",
    "row=2\n",
    "for f in os.listdir(txt_path): \n",
    "    if os.path.isfile(os.path.join(txt_path, f)):\n",
    "        ws1['A' + str(row)]= f\n",
    "        fname=txt_path + \"/\" + f\n",
    "        if \"_\" in f :\n",
    "            elems = f.split(\"_\")\n",
    "            city = elems[0]\n",
    "            year = elems[1]\n",
    "            ws1['B' + str(row)]= city\n",
    "            ws1['C' + str(row)]= year\n",
    "        frequencies = Counter(open(fname,'r').read().split())\n",
    "        col=4\n",
    "        with open(\"../data/rues.txt\", 'r') as recherche:\n",
    "            for line in recherche:\n",
    "                lettre=get_column_letter(col)\n",
    "                ws1[lettre + str(row)]= frequencies[line.strip()]\n",
    "                col+=1\n",
    "        row+=1\n",
    "                \n",
    "maxrow=len(ws1['A'])\n",
    "maxcol=ws1.max_column\n",
    "ws1['A'+ str(maxrow+1)]=\"Total frequence\"\n",
    "total=0\n",
    "col=4\n",
    "while col <= maxcol:\n",
    "    lettre=get_column_letter(col)\n",
    "    for row in range(2,maxrow):\n",
    "        total+=int(ws1[lettre + str(row)].value)\n",
    "    ws1[lettre + str(maxrow+1)]=total\n",
    "    if total==0:\n",
    "#        print((ws1[lettre + str(1)].value).strip() + \" éliminé\")\n",
    "        ws1.delete_cols(col)\n",
    "        col=col-1\n",
    "        maxcol=maxcol-1\n",
    "    total=0\n",
    "    col+=1\n",
    "\n",
    "\n",
    "\n",
    "lettre1=get_column_letter(maxcol+1)\n",
    "ws1[lettre1+ str(1)]=\"Total frequence\"\n",
    "total=0\n",
    "row=2\n",
    "while row <=maxrow:\n",
    "    for col in range(4,maxcol):\n",
    "        lettre=get_column_letter(col)\n",
    "        total+=ws1[lettre + str(row)].value\n",
    "    ws1[lettre1 + str(row)]=total\n",
    "    if total<=10:\n",
    "#        print((ws1['A' + str(row)].value).strip() + \" éliminé\")\n",
    "        ws1.delete_rows(row)\n",
    "        row=row-1\n",
    "        maxrow=maxrow-1\n",
    "    total=0\n",
    "    row+=1\n",
    "\n",
    "wb.save(dest_filename) \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2348eae-3147-4875-a385-28dda412863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filtrer le corpus à l'aide des mots mis dans la liste de recherche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2234f688-4f8e-4c63-9721-069d8aeb4379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n"
     ]
    }
   ],
   "source": [
    "# Rassembler tous ces fichiers en un seul document tp4_all.txt en ajoutant un marquage pour indiquer sur quelle année porte le bulletin. \n",
    "#Nous éliminons au passage tous les bulletins de Bruxelles antérieurs à 1920 \n",
    "\n",
    "filename = '../data/frequences.xlsx'\n",
    "txt_path = '../data/tmp'\n",
    "content_list = []\n",
    "workbook = openpyxl.load_workbook(filename)\n",
    "ws1 = wb.active\n",
    "compteur=0\n",
    "\n",
    "maxrow=(len(ws1['A']))-1\n",
    "maxcol=(ws1.max_column)-1\n",
    "row=2\n",
    "while row <=maxrow-1:\n",
    "    string_deb=\"$$$$$$$$$$\" + \"\\n\"\n",
    "    file=ws1['A' + str(row)].value\n",
    "    city=ws1['B' + str(row)].value\n",
    "    year=ws1['C' + str(row)].value\n",
    "    if (city==\"Bxl\" and int(year)>=1920) or city==\"Lkn\":\n",
    "        content_list.append(\"$$$$$$$$$$\"+ year + \"\\n\")\n",
    "        compteur+=1\n",
    "    with open(os.path.join(txt_path, file), 'r') as bulletin:\n",
    "        content_list.append(bulletin.read())\n",
    "    row+=1    \n",
    "\n",
    "print(str(compteur))\n",
    "temp_path = '../data'\n",
    "with open('../data/tp4_all.txt', 'w') as f:\n",
    "    f.write(' '.join(content_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9f7c53-ac96-422e-a48f-88fe551a286e",
   "metadata": {},
   "source": [
    "## Nettoyer le fichier à l'aide d'une fonction de nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5c48554-83b5-43b2-9c1f-febd2e446172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopwords (Idem que dans s1) _ repris du TP3\n",
    "sw = stopwords.words(\"french\")\n",
    "sw += [\"abord\", \"acceptée\", \"accord\", \"accorder\", \"acte\", \"action\", \"actuel\", \"adjudication\", \"administration\", \"admis\", \"adopté\", \"adoptées\", \"adoption\", \n",
    "       \"adresse\", \"adressées\", \"affaire\", \"afin\", \"agit\", \"ailleurs\", \"ainsi\", \"ajouter\", \"alors\", \"amendement\", \"anderlecht\", \"année\", \"années\", \"annuel\", \"ans\", \"août\", \n",
    "       \"appartenant\", \"appel\", \"application\", \"approbation\", \"approuvé\", \"après\", \"ares\", \"argent\", \"arrêté\", \"art\", \"article\", \"articles\", \"assez\", \n",
    "       \"assurer\", \"aucun\", \"aucune\", \"augmenter\", \"aujourd\", \"aussi\", \"autant\", \"auteur\", \"autorisation\", \"autorisé\", \"autoriser\", \"autorité\", \"autre\", \n",
    "       \"autres\", \"avant\", \"avenir\", \"avenue\", \"avis\", \"avoir\", \"avril\", \"bas\", \"base\", \"bases\", \"bâtiment\", \"bâtiments\", \"bâtisses\", \"beaucoup\", \"beaux\", \n",
    "       \"besoin\", \"besoins\", \"bien\", \"bienfaisance\", \"biens\", \"bon\", \"boulangerie\", \"boulevard\", \"bourgmestre\", \"bruxelles\", \"bulletin\", \"bureau\", \"bureaux\", \n",
    "       \"but\", \"caisse\", \"car\", \"carrés\", \"cas\", \"cause\", \"cela\", \"celle\", \"celles\", \"celte\", \"celui\", \"cent\", \"centiares\", \"centimes\", \"centimètres\", \n",
    "       \"cependant\", \"certain\", \"certaines\", \"certains\", \"cet\", \"cette\", \"ceux\", \"chacun\", \"chapitre\", \"chaque\", \"charge\", \"charger\", \"charges\", \"charité\", \n",
    "       \"chaussée\", \"chef\", \"chez\", \"chiffre\", \"chiffres\", \"chose\", \"choses\", \"cinq\", \"circonstances\", \"classe\", \"collège\", \"collègue\", \"comité\", \"comme\", \n",
    "       \"comment\", \"commission\", \"communal\", \"communale\", \"communales\", \"communaux\", \"commune\", \"communes\", \"compagnie\", \"compagnies\", \"compris\", \"compte\", \n",
    "       \"concerne\", \"concession\", \"conclusion\", \"conclusions\", \"condition\", \"conditions\", \"conformément\", \"connaissance\", \"connaître\", \"conseil\", \n",
    "       \"conseillers\", \"conséquence\", \"considérable\", \"considérables\", \"considère\", \"contenance\", \"contentieux\", \"contraire\", \"contrat\", \"contre\", \"convention\", \"côté\", \n",
    "       \"courant\", \"cours\", \"créances\", \"créer\", \"crois\", \"dame\", \"date\", \"décembre\", \"décembre.\", \"décision\", \"déclaration\", \"dehors\", \"déjà\", \"delà\", \n",
    "       \"délai\", \"délibération\", \"demande\", \"demandé\", \"demander\", \"demandes\", \"demeurant\", \"dépôt\", \"depuis\", \"députation\", \"dêputation\", \"dernier\", \n",
    "       \"dernière\", \"dès\", \"dessus\", \"deux\", \"deuxième\", \"devant\", \"devis\", \"devoir\", \"devons\", \"devront\", \"différence\", \"difficile\", \"difficultés\", \n",
    "       \"dire\", \"direction\", \"discussion\", \"disposition\", \"dispositions\", \"dit\", \"divers\", \"diverses\", \"division\", \"dix\", \"doit\", \"doivent\", \"donation\", \n",
    "       \"donc\", \"donne\", \"donné\", \"donnée\", \"donner\", \"dont\", \"double\", \"doute\", \"droits\", \"echevin\", \"échevin\", \"echevins\", \"échevins\", \"effet\", \"également\", \n",
    "       \"égard\", \"église\", \"élevé\", \"elles\", \"émettre\", \"emplacement\", \"emploi\", \"encore\", \"enfin\", \"engage\", \"enquête\", \"ensemble\", \"ensuite\", \"entendu\", \n",
    "       \"entre\", \"entrée\", \"entreprise\", \"environ\", \"époque\", \"ester\", \"établi\", \"établir\", \"établissement\", \"établissements\", \"etat\", \"état\", \"etc\", \"être\", \n",
    "       \"etterbeek\", \"étude\", \"évaluation\", \"évaluations\", \"examen\", \"exécuter\", \"exécution\", \"exemple\", \"exercice\", \"existe\", \"extraordinaires\", \"fabrique\", \"face\", \n",
    "       \"facile\", \"façon\", \"faire\", \"fait\", \"faite\", \"faites\", \"faits\", \"famille\", \"faudrait\", \"faut\", \"favorable\", \"fera\", \"février\", \"filles\", \"fixé\", \n",
    "       \"fois\", \"fonds\", \"font\", \"forme\", \"fort\", \"frais\", \"francs\", \"garde\", \"général\", \"générale\", \"grand\", \"grande\", \"grandes\", \"grands\", \"grandvelle\", \n",
    "       \"habitants\", \"habitations\", \"haut\", \"haute\", \"herpels\", \"het\", \"heure\", \"heures\", \"hommes\", \"honneur\", \"honorable\", \"hospice\", \"hospices\", \"hôtel\", \"hui\", \n",
    "       \"huit\", \"ici\", \"idée\", \"idem\", \"ils\", \"immédiatement\", \"immeuble\", \"immeubles\", \"impasse\", \"impasses\", \"importance\", \"impossible\", \"inconvénient\", \"inconvénients\", \n",
    "       \"indispensable\", \"industrie\", \"informe\", \"inscription\", \"instruction\", \"intenter\", \"intérêt\", \"intérêts\", \"jamais\", \"janvier\", \"jean\", \"jour\", \"jours\", \"juillet\", \n",
    "       \"juin\", \"jusqu\", \"juste\", \"justice\", \"kil\", \"laeken\", \"laisser\", \"laquelle\", \"lecture\", \"legs\", \"lequel\", \"les\", \"lettre\", \"lettres\", \"leurs\", \"libre\", \"lieu\", \n",
    "       \"liste\", \"lit\", \"local\", \"location\", \"locaux\", \"loi\", \"loin\", \"longtemps\", \"lors\", \"lorsqu\", \"lorsque\", \"lot\", \"mai\", \"maintenant\", \"maison\", \n",
    "       \"maisons\", \"malgré\", \"manière\", \"marchai\", \"mars\", \"matériaux\", \"matières\", \"matin\", \"membre\", \"membres\", \"mêmes\", \"ménage\", \"messieurs\", \"mesures\", \n",
    "       \"mètre\", \"mètres\", \"mettre\", \"mieux\", \"mille\", \"millions\", \"minimes\", \"mis\", \"moins\", \"mois\", \"moment\", \"montant\", \"mots\", \"mouvement\", \"moyen\", \n",
    "       \"moyenne\", \"moyens\", \"nature\", \"nécessaire\", \"nécessaires\", \"nécessité\", \"neuf\", \"noires\", \"nom\", \"nombre\", \"nombreux\", \"non\", \"notaire\", \"nouveau\", \n",
    "       \"nouveaux\", \"nouvelle\", \"nouvelles\", \"novembre\", \"objet\", \"objets\", \"observation\", \"observations\", \"obtenir\", \"obtenu\", \"occasion\", \"octobre\", \n",
    "       \"officiers\", \"onze\", \"opinion\", \"ordinaires\", \"ordonnance\", \"ordre\", \"outre\", \"ouverte\", \"ouverture\", \"paiement\", \"pain\", \"paraît\", \"parce\", \n",
    "       \"parfaitement\", \"parmi\", \"part\", \"partie\", \"parties\", \"partir\", \"passé\", \"payer\", \"pays\", \"pendant\", \"pense\", \"permanente\", \"perpétuité\", \"personne\", \"personne\", \n",
    "       \"personnel\", \"personnelle\", \"personnes\", \"petit\", \"petite\", \"peu\", \"peut\", \"peuvent\", \"pièces\", \"pierre\", \"pierres\", \"place\", \"plus\", \"plusieurs\", \n",
    "       \"point\", \"populaire\", \"population\", \"portant\", \"porté\", \"portée\", \"position\", \"possible\", \"pourquoi\", \"pourra\", \"pourrait\", \"pouvoir\", \n",
    "       \"pouvons\", \"premier\", \"première\", \"prendre\", \"près\", \"présence\", \"présent\", \"présente\", \"présenté\", \"présenter\", \"présents\", \"principal\", \n",
    "       \"principale\", \"principe\", \"pris\", \"procédé\", \"procès\", \"prochain\", \"prochaine\", \"produit\", \"profit\", \"proportion\", \"propose\", \"proposé\", \"proposer\", \n",
    "       \"proposition\", \"propositions\", \"propriétaire\", \"propriétaires\", \"propriété\", \"propriétés\", \"provincial\", \"provisoire\", \"public\", \"publics\", \"publique\", \n",
    "       \"publiques\", \"puis\", \"puisque\", \"puisse\", \"pyck\", \"quand\", \"quant\", \"quartier\", \"quatre\", \"quelque\", \"quelques\", \"question\", \"questions\", \"quoi\", \"raison\", \n",
    "       \"rapport\", \"rapports\", \"receveur\", \"recevoir\", \"réclamation\", \"réclamations\", \"reçu\", \"règlement\", \"relatif\", \"relatives\", \"remarquer\", \n",
    "       \"remboursement\", \"rendre\", \"renseignements\", \"rentes\", \"renvoi\", \"résolution\", \"ressources\", \"reste\", \"résultat\", \"résulte\", \"rien\", \n",
    "       \"rue\", \"rues\", \"saint\", \"sainte\", \"salle\", \"salles\", \"sans\", \"sauf\", \"savoir\", \"seance\", \"séance\", \"second\", \"seconde\", \"secours\", \n",
    "       \"secrétaire\", \"secrétariat\", \"section\", \"sections\", \"semble\", \"sens\", \"sept\", \"septembre\", \"sépulture\", \"service\", \"seul\", \"seule\", \n",
    "       \"seulement\", \"sieur\", \"simple\", \"sise\", \"situation\", \"situé\", \"situés\", \"six\", \"société\", \"sociétés\", \"sœurs\", \"sollicite\", \"solution\", \n",
    "       \"sorte\", \"soumettre\", \"soumis\", \"soumission\", \"soumissions\", \"sous\", \"souvent\", \"suit\", \"suite\", \"suivant\", \"suivante\", \"suivantes\", \"suivants\", \n",
    "       \"sujet\", \"supérieure\", \"supplémentaire\", \"surtout\", \"système\", \"tableau\", \"tandis\", \"tant\", \"tard\", \"tel\", \"telle\", \"temps\", \"tendant\", \n",
    "       \"termes\", \"terrain\", \"terrains\", \"territoire\", \"titre\", \"total\", \"toujours\", \"tous\", \"tout\", \"toute\", \"toutes\", \"transmettre\", \"travai\", \n",
    "       \"travail\", \"très\", \"trois\", \"troisième\", \"trop\", \"trouve\", \"trouvent\", \"trouver\", \"trouvés\", \"unanimité\", \"usage\", \"utilité\", \"valeur\", \n",
    "       \"van\", \"vanhelst\", \"vend\", \"vendre\", \"verbal\", \"verbal\", \"vers\", \"veuve\", \"vient\", \"vieux\", \"ville\", \"villes\", \"vingt\", \"vis\", \"voici\", \n",
    "       \"voir\", \"voix\", \"volume\", \"vote\", \"voté\", \"voter\", \"voyez\", \"vrai\", \"vue\"]\n",
    "sw = set(sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7acc806-7742-452d-bf71-5575a284bf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(filein,fileout):\n",
    "    input_path = filein\n",
    "    output_path = fileout\n",
    "    output = open(output_path, \"w\", encoding='utf-8')\n",
    "    with open(input_path, encoding='utf-8') as f:\n",
    "        text = f.read()\n",
    "        words = nltk.wordpunct_tokenize(text)\n",
    "        kept = [w.lower() for w in words if len(w) > 2 and w.isalpha() and w.lower() not in sw]\n",
    "        kept_string = \" \".join(kept)\n",
    "        output.write(kept_string)\n",
    "    return f'Output has been written in {output_path}!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee57cc60-459b-4964-b366-4fe70b43c265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output has been written in ../data/tp4_all_clean.txt!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text('../data/tp4_all.txt', '../data/tp4_all_clean.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b07d98-a842-4f68-890c-cf22281b29f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Nuage de mots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a7231d-ebf3-49cd-934a-0b20da03dd93",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Afficher les termes les plus fréquents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd99fbbe-5e27-4b49-a9d5-ab86ac63806c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('travaux', 30364), ('budget', 26262), ('intervention', 17250), ('ecole', 16207), ('dépenses', 15624), ('dépense', 14446), ('recettes', 13936), ('police', 12709), ('assistance', 12636), ('prix', 12531), ('projet', 12486), ('enfants', 12351), ('école', 11898), ('enseignement', 11388), ('nomination', 11212), ('monsieur', 11067), ('construction', 10929), ('crédit', 10500), ('professeur', 10414), ('een', 10412), ('mesdames', 10369), ('écoles', 10336), ('services', 9528), ('voor', 9314), ('élèves', 9290), ('entretien', 9132), ('taxe', 8981), ('somme', 8921), ('gaz', 8796), ('scolaire', 8641), ('plan', 7875), ('vente', 7856), ('dat', 7759), ('droit', 7741), ('mise', 7583), ('considérant', 7540), ('hôpital', 7176), ('aan', 7078), ('subside', 6908), ('exposition', 6855), ('royal', 6506), ('voie', 6258), ('institut', 6241), ('primaire', 6111), ('finances', 6088), ('eau', 6083), ('aménagement', 6075), ('fin', 6048), ('augmentation', 5972), ('fonctions', 5915), ('création', 5879), ('die', 5837), ('eglise', 5719), ('brunfaut', 5695), ('président', 5667), ('centre', 5652), ('qualité', 5502), ('modification', 5445), ('actuellement', 5326), ('démission', 5310), ('met', 5285), ('arts', 5222), ('installations', 5181), ('over', 5115), ('voudrais', 5095), ('installation', 5066), ('chauffage', 5042), ('notamment', 5014), ('pensions', 4992), ('extraordinaire', 4967), ('crédits', 4773), ('worden', 4721), ('matériel', 4675), ('tôt', 4516), ('gouvernement', 4515), ('marché', 4508), ('directeur', 4503), ('belgique', 4480), ('mesure', 4463), ('heer', 4434), ('don', 4406), ('subsides', 4394), ('normale', 4324), ('achat', 4310), ('problème', 4303), ('théâtre', 4261), ('voirie', 4235), ('conseiller', 4230), ('circulation', 4205), ('ministre', 4139), ('renouvellement', 4124), ('modifications', 4121), ('éclairage', 4114), ('agents', 4098), ('palais', 4090), ('ouvriers', 4081), ('technique', 4068), ('bruxellois', 4067), ('répond', 4062), ('zijn', 4016), ('traitement', 4006), ('jeunes', 3951), ('parc', 3934), ('district', 3934), ('acquisition', 3927), ('classes', 3904), ('actes', 3891), ('chargé', 3889), ('ancien', 3875), ('traitements', 3868), ('parole', 3849), ('rons', 3849), ('bruxelloise', 3848), ('plans', 3844), ('der', 3834), ('pension', 3794), ('mot', 3752), ('études', 3711), ('royale', 3702), ('schalckens', 3700), ('door', 3698), ('fourniture', 3694), ('ecoles', 3686), ('groupe', 3683), ('porte', 3668), ('emile', 3666), ('bois', 3656), ('dispy', 3643), ('commerce', 3635), ('den', 3593), ('institutrice', 3590), ('relative', 3587), ('matière', 3547), ('cahier', 3531), ('ordinaire', 3530), ('voies', 3529), ('exploitation', 3493), ('deze', 3492), ('lepage', 3482), ('remise', 3458), ('désignation', 3441), ('primaires', 3431), ('niet', 3371), ('nominal', 3352), ('définitif', 3337), ('agglomération', 3324), ('belge', 3321), ('hôpitaux', 3303), ('heren', 3287), ('province', 3279), ('marie', 3261), ('organisation', 3253), ('charles', 3239), ('brugmann', 3232), ('supplémentaires', 3191), ('greef', 3157), ('eaux', 3144), ('électricité', 3144), ('compétent', 3135), ('centrale', 3120), ('totaux', 3089), ('placement', 3061), ('professionnelle', 3061), ('fer', 3058), ('projets', 3055), ('ligne', 3053), ('restauration', 3033), ('corps', 3014), ('faveur', 2991), ('nationale', 2976), ('taxes', 2972), ('emprunt', 2970), ('attention', 2962), ('cooremans', 2954), ('jardin', 2950), ('texte', 2935), ('tramways', 2929), ('ixelles', 2925), ('bonne', 2915), ('suppression', 2910), ('brouhon', 2907), ('soir', 2901), ('transports', 2890), ('concours', 2886), ('politique', 2864), ('programme', 2849), ('scolaires', 2847), ('salaires', 2842), ('professeurs', 2830), ('voitures', 2820), ('heembeek', 2818), ('administrative', 2817), ('constructions', 2814), ('concernant', 2805), ('hebben', 2799), ('effectuer', 2798), ('heysel', 2787), ('thielemans', 2784), ('majoration', 2760), ('ancienne', 2758)]\n"
     ]
    }
   ],
   "source": [
    "with open('../data/tp4_all_clean.txt', 'r') as f:\n",
    "    after = f.read()\n",
    "\n",
    "frequencies = Counter(after.split())\n",
    "\n",
    "print(frequencies.most_common(200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ed6d2-7ccb-4cc3-bbdf-caaf27c9e3ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Créer, stocker et afficher le nuage de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f21210-2e31-4636-a035-af9a1bec47f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cloud = WordCloud(width=2000, height=1000, background_color='white').generate_from_frequencies(frequencies)\n",
    "cloud.to_file(os.path.join(temp_path, f\"{year}.png\"))\n",
    "Image(filename=os.path.join(temp_path, f\"{year}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c4eb69b-4088-43bb-8e31-757bdf436ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belgique apparait 21 fois dans le corpus\n",
      "paris apparait 16 fois dans le corpus\n",
      "namur apparait 15 fois dans le corpus\n",
      "luxembourg apparait 12 fois dans le corpus\n",
      "gand apparait 9 fois dans le corpus\n",
      "derammeleer apparait 9 fois dans le corpus\n",
      "josse apparait 8 fois dans le corpus\n",
      "ixelles apparait 8 fois dans le corpus\n",
      "pachéco apparait 8 fois dans le corpus\n",
      "athénée apparait 8 fois dans le corpus\n",
      "france apparait 7 fois dans le corpus\n",
      "londres apparait 7 fois dans le corpus\n",
      "maelbeék apparait 6 fois dans le corpus\n",
      "étang josse ten noode apparait 6 fois dans le corpus\n",
      "étang josse ten apparait 5 fois dans le corpus\n",
      "bogards apparait 5 fois dans le corpus\n",
      "steenpoort apparait 5 fois dans le corpus\n",
      "somme apparait 4 fois dans le corpus\n",
      "cologne apparait 4 fois dans le corpus\n",
      "decoen apparait 4 fois dans le corpus\n",
      "waterloo apparait 4 fois dans le corpus\n",
      "anvers apparait 3 fois dans le corpus\n",
      "jaugeages apparait 3 fois dans le corpus\n",
      "new york apparait 3 fois dans le corpus\n",
      "vanderelst apparait 3 fois dans le corpus\n",
      "gudule apparait 3 fois dans le corpus\n",
      "verheyden bavière apparait 3 fois dans le corpus\n",
      "limbourg apparait 3 fois dans le corpus\n",
      "canal charleroy apparait 2 fois dans le corpus\n",
      "mertens apparait 2 fois dans le corpus\n",
      "confisde apparait 2 fois dans le corpus\n",
      "allemagne apparait 2 fois dans le corpus\n",
      "uccle apparait 2 fois dans le corpus\n",
      "porte namur apparait 2 fois dans le corpus\n",
      "clabecq apparait 2 fois dans le corpus\n",
      "carez apparait 2 fois dans le corpus\n",
      "flandre apparait 2 fois dans le corpus\n",
      "suprà apparait 2 fois dans le corpus\n",
      "mécompte apparait 2 fois dans le corpus\n",
      "mont apparait 2 fois dans le corpus\n",
      "belges apparait 2 fois dans le corpus\n",
      "esplanade namur apparait 2 fois dans le corpus\n",
      "derre apparait 2 fois dans le corpus\n",
      "canal flandre apparait 2 fois dans le corpus\n",
      "vanobberghen apparait 2 fois dans le corpus\n",
      "morgendstar apparait 2 fois dans le corpus\n",
      "goossens apparait 2 fois dans le corpus\n",
      "thisselt apparait 2 fois dans le corpus\n",
      "vanderzypen apparait 2 fois dans le corpus\n",
      "steenport apparait 2 fois dans le corpus\n"
     ]
    }
   ],
   "source": [
    "#reconnaissance d'entités nommée par très utile pour cet exercice\n",
    "\n",
    "n=900000\n",
    "text = open(\"../data/tp4_all_clean.txt\", encoding='utf-8').read()[:n]\n",
    "doc = nlp(text)\n",
    "localite = defaultdict(int)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"LOC\" and len(ent.text) > 3:\n",
    "        localite[ent.text] += 1\n",
    "        \n",
    "sorted_localite = sorted(localite.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for loca, freq in sorted_localite[:50]:\n",
    "    print(f\"{loca} apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fd4b8-e51a-414f-a9dd-c1d76c8c93dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
